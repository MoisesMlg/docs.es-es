---
title: Métricas de ML.NET
description: Introducción a las métricas que se utilizan para evaluar el rendimiento de un modelo de ML.NET
ms.date: 12/17/2019
ms.openlocfilehash: 046e0a3feea2da702dfef5ca9ce4f498fce5fb26
ms.sourcegitcommit: 0802ac583585110022beb6af8ea0b39188b77c43
ms.translationtype: HT
ms.contentlocale: es-ES
ms.lasthandoff: 11/26/2020
ms.locfileid: "91804827"
---
# <a name="evaluate-your-mlnet-model-with-metrics"></a><span data-ttu-id="e8471-103">Evaluación de su modelo de ML.NET con métricas</span><span class="sxs-lookup"><span data-stu-id="e8471-103">Evaluate your ML.NET model with metrics</span></span>

<span data-ttu-id="e8471-104">Comprenda las métricas empleadas para evaluar un modelo de ML.NET.</span><span class="sxs-lookup"><span data-stu-id="e8471-104">Understand the metrics used to evaluate an ML.NET model.</span></span>

<span data-ttu-id="e8471-105">Las métricas de evaluación son específicas del tipo de tarea de aprendizaje automático que realiza un modelo.</span><span class="sxs-lookup"><span data-stu-id="e8471-105">Evaluation metrics are specific to the type of machine learning task that a model performs.</span></span>

<span data-ttu-id="e8471-106">Por ejemplo, para la tarea de clasificación, el modelo se evalúa midiendo el grado de coincidencia de una categoría predicha con la categoría real.</span><span class="sxs-lookup"><span data-stu-id="e8471-106">For example, for the classification task, the model is evaluated by measuring how well a predicted category matches the actual category.</span></span> <span data-ttu-id="e8471-107">Y, para la agrupación en clústeres, la evaluación se basa en lo próximos que están unos de otros los elementos agrupados y en el grado de separación existente entre los clústeres.</span><span class="sxs-lookup"><span data-stu-id="e8471-107">And for clustering, evaluation is based on how close clustered items are to each other, and how much separation there is between the clusters.</span></span>

## <a name="evaluation-metrics-for-binary-classification"></a><span data-ttu-id="e8471-108">Métricas de evaluación para la clasificación binaria</span><span class="sxs-lookup"><span data-stu-id="e8471-108">Evaluation metrics for Binary Classification</span></span>

| <span data-ttu-id="e8471-109">Métricas</span><span class="sxs-lookup"><span data-stu-id="e8471-109">Metrics</span></span>   |      <span data-ttu-id="e8471-110">Descripción</span><span class="sxs-lookup"><span data-stu-id="e8471-110">Description</span></span>      |  <span data-ttu-id="e8471-111">Buscar</span><span class="sxs-lookup"><span data-stu-id="e8471-111">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="e8471-112">**Precisión**</span><span class="sxs-lookup"><span data-stu-id="e8471-112">**Accuracy**</span></span> |  <span data-ttu-id="e8471-113">La [precisión](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) es la proporción de predicciones correctas con un conjunto de datos de prueba.</span><span class="sxs-lookup"><span data-stu-id="e8471-113">[Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) is the proportion of correct predictions with a test data set.</span></span> <span data-ttu-id="e8471-114">Es la relación entre el número de predicciones correctas y el número total de ejemplos de entrada.</span><span class="sxs-lookup"><span data-stu-id="e8471-114">It is the ratio of number of correct predictions to the total number of input samples.</span></span> <span data-ttu-id="e8471-115">Funciona bien si hay un número similar de muestras que pertenecen a cada clase.</span><span class="sxs-lookup"><span data-stu-id="e8471-115">It works well if there are similar number of samples belonging to each class.</span></span>| <span data-ttu-id="e8471-116">**Cuanto más cerca de 1,00, mejor**.</span><span class="sxs-lookup"><span data-stu-id="e8471-116">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="e8471-117">Pero exactamente 1,00 indica un problema (normalmente: fuga de etiqueta/destino, sobreajuste o pruebas con datos de entrenamiento).</span><span class="sxs-lookup"><span data-stu-id="e8471-117">But exactly 1.00 indicates an issue (commonly: label/target leakage, over-fitting, or testing with training data).</span></span> <span data-ttu-id="e8471-118">Cuando los datos de prueba están desequilibrados (donde la mayoría de las instancias pertenece a una de las clases), el conjunto de datos es pequeño o las puntuaciones se acercan a 0,00 o 1,00, la precisión no captura realmente la eficacia de un clasificador y es necesario comprobar métricas adicionales.</span><span class="sxs-lookup"><span data-stu-id="e8471-118">When the test data is unbalanced (where most of the instances belong to one of the classes), the dataset is small, or scores approach 0.00 or 1.00, then accuracy doesn't really capture the effectiveness of a classifier and you need to check additional metrics.</span></span> |
| <span data-ttu-id="e8471-119">**AUC**</span><span class="sxs-lookup"><span data-stu-id="e8471-119">**AUC**</span></span> |    <span data-ttu-id="e8471-120">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) o *Área bajo la curva* mide el área bajo la curva que se creó limpiando la tasa de positivos verdaderos frente a la tasa de falsos positivos.</span><span class="sxs-lookup"><span data-stu-id="e8471-120">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) or *Area under the curve* measures the area under the curve created by sweeping the true positive rate vs. the false positive rate.</span></span>  |   <span data-ttu-id="e8471-121">**Cuanto más cerca de 1,00, mejor**.</span><span class="sxs-lookup"><span data-stu-id="e8471-121">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="e8471-122">Debe ser mayor que 0,50 para que un modelo sea aceptable.</span><span class="sxs-lookup"><span data-stu-id="e8471-122">It should be greater than 0.50 for a model to be acceptable.</span></span> <span data-ttu-id="e8471-123">Un modelo con AUC de 0,50 o menos no tiene ningún valor.</span><span class="sxs-lookup"><span data-stu-id="e8471-123">A model with AUC of 0.50 or less is worthless.</span></span> |
| <span data-ttu-id="e8471-124">**AUCPR**</span><span class="sxs-lookup"><span data-stu-id="e8471-124">**AUCPR**</span></span> | <span data-ttu-id="e8471-125">aucPR o *Área bajo la curva de una curva de precisión-recuperación*: Medida útil de éxito de predicción cuando las clases están poco equilibradas (conjuntos de datos muy sesgados).</span><span class="sxs-lookup"><span data-stu-id="e8471-125">aucPR or *Area under the curve of a Precision-Recall curve*: Useful measure of success of prediction when the classes are imbalanced (highly skewed datasets).</span></span> |  <span data-ttu-id="e8471-126">**Cuanto más cerca de 1,00, mejor**.</span><span class="sxs-lookup"><span data-stu-id="e8471-126">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="e8471-127">Las puntuaciones altas cercanas a 1,00 muestran que el clasificador devuelve resultados precisos (alta precisión), así como una mayoría de todos los resultados positivos (recuperación alta).</span><span class="sxs-lookup"><span data-stu-id="e8471-127">High scores close to 1.00 show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).</span></span> |
| <span data-ttu-id="e8471-128">**Puntuación F1**</span><span class="sxs-lookup"><span data-stu-id="e8471-128">**F1-score**</span></span> | <span data-ttu-id="e8471-129">La [puntuación F1](https://en.wikipedia.org/wiki/F1_score) también se denomina *puntuación F equilibrada o F medida F*.</span><span class="sxs-lookup"><span data-stu-id="e8471-129">[F1 score](https://en.wikipedia.org/wiki/F1_score) also known as *balanced F-score or F-measure*.</span></span> <span data-ttu-id="e8471-130">Es la media armónica de la precisión y la recuperación.</span><span class="sxs-lookup"><span data-stu-id="e8471-130">It's the harmonic mean of the precision and recall.</span></span> <span data-ttu-id="e8471-131">La puntuación F1 resulta útil cuando desea buscar un equilibrio entre la precisión y la recuperación.</span><span class="sxs-lookup"><span data-stu-id="e8471-131">F1 Score is helpful when you want to seek a balance between Precision and Recall.</span></span>| <span data-ttu-id="e8471-132">**Cuanto más cerca de 1,00, mejor**.</span><span class="sxs-lookup"><span data-stu-id="e8471-132">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="e8471-133">Una puntuación F1 alcanza el mejor valor en 1,00 y la peor puntuación en 0,00.</span><span class="sxs-lookup"><span data-stu-id="e8471-133">An F1 score reaches its best value at 1.00 and worst score at 0.00.</span></span> <span data-ttu-id="e8471-134">Indica cuán preciso es el clasificador.</span><span class="sxs-lookup"><span data-stu-id="e8471-134">It tells you how precise your classifier is.</span></span> |

<span data-ttu-id="e8471-135">Para obtener más información sobre las métricas de clasificación binaria, lea los artículos siguientes:</span><span class="sxs-lookup"><span data-stu-id="e8471-135">For further details on binary classification metrics read the following articles:</span></span>

- [<span data-ttu-id="e8471-136">¿Exactitud, precisión, recuperación o F1?</span><span class="sxs-lookup"><span data-stu-id="e8471-136">Accuracy, Precision, Recall, or F1?</span></span>](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)
- [<span data-ttu-id="e8471-137">Clase de métricas para la clasificación binaria</span><span class="sxs-lookup"><span data-stu-id="e8471-137">Binary Classification Metrics class</span></span>](xref:Microsoft.ML.Data.BinaryClassificationMetrics)
- [<span data-ttu-id="e8471-138">La relación entre precisión-recuperación y curvas de ROC</span><span class="sxs-lookup"><span data-stu-id="e8471-138">The Relationship Between Precision-Recall and ROC Curves</span></span>](http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf)

## <a name="evaluation-metrics-for-multi-class-classification"></a><span data-ttu-id="e8471-139">Métricas de evaluación para la clasificación multiclase</span><span class="sxs-lookup"><span data-stu-id="e8471-139">Evaluation metrics for Multi-class Classification</span></span>

| <span data-ttu-id="e8471-140">Métricas</span><span class="sxs-lookup"><span data-stu-id="e8471-140">Metrics</span></span>   |      <span data-ttu-id="e8471-141">Descripción</span><span class="sxs-lookup"><span data-stu-id="e8471-141">Description</span></span>      |  <span data-ttu-id="e8471-142">Buscar</span><span class="sxs-lookup"><span data-stu-id="e8471-142">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="e8471-143">**Microprecisión**</span><span class="sxs-lookup"><span data-stu-id="e8471-143">**Micro-Accuracy**</span></span> |  <span data-ttu-id="e8471-144">La [precisión de micropromedio](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) agrega las contribuciones de todas las clases para calcular la métrica promedio.</span><span class="sxs-lookup"><span data-stu-id="e8471-144">[Micro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) aggregates the contributions of all classes to compute the average metric.</span></span> <span data-ttu-id="e8471-145">Es la fracción de instancias que se predijeron correctamente.</span><span class="sxs-lookup"><span data-stu-id="e8471-145">It is the fraction of instances predicted correctly.</span></span> <span data-ttu-id="e8471-146">El micropromedio no tiene en cuenta la pertenencia a una clase.</span><span class="sxs-lookup"><span data-stu-id="e8471-146">The micro-average does not take class membership into account.</span></span> <span data-ttu-id="e8471-147">Básicamente, todos los pares de ejemplo y clase contribuyen del mismo modo a la métrica de precisión.</span><span class="sxs-lookup"><span data-stu-id="e8471-147">Basically, every sample-class pair contributes equally to the accuracy metric.</span></span> | <span data-ttu-id="e8471-148">**Cuanto más cerca de 1,00, mejor**.</span><span class="sxs-lookup"><span data-stu-id="e8471-148">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="e8471-149">En una tarea de clasificación multiclase, la microprecisión es preferible a la macroprecisión si se sospecha que podría haber un desequilibrio de clases (por ejemplo,</span><span class="sxs-lookup"><span data-stu-id="e8471-149">In a multi-class classification task, micro-accuracy is preferable over macro-accuracy if you suspect there might be class imbalance (i.e</span></span> <span data-ttu-id="e8471-150">podría tener muchos más ejemplos de una clase que de otras clases).</span><span class="sxs-lookup"><span data-stu-id="e8471-150">you may have many more examples of one class than of other classes).</span></span>|
| <span data-ttu-id="e8471-151">**Macroprecisión**</span><span class="sxs-lookup"><span data-stu-id="e8471-151">**Macro-Accuracy**</span></span> | <span data-ttu-id="e8471-152">La [precisión de macropromedio](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) es la precisión promedio en el nivel de clase.</span><span class="sxs-lookup"><span data-stu-id="e8471-152">[Macro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) is the average accuracy at the class level.</span></span> <span data-ttu-id="e8471-153">La precisión de cada clase se calcula y la macroprecisión es el promedio de estas precisiones.</span><span class="sxs-lookup"><span data-stu-id="e8471-153">The accuracy for each class is computed and the macro-accuracy is the average of these accuracies.</span></span> <span data-ttu-id="e8471-154">Básicamente, todas las clases contribuyen del mismo modo a la métrica de precisión.</span><span class="sxs-lookup"><span data-stu-id="e8471-154">Basically, every class contributes equally to the accuracy metric.</span></span> <span data-ttu-id="e8471-155">Las clases minoritarias tienen el mismo peso que las clases más grandes.</span><span class="sxs-lookup"><span data-stu-id="e8471-155">Minority classes are given equal weight as the larger classes.</span></span> <span data-ttu-id="e8471-156">La métrica de macropromedio proporciona el mismo peso a cada clase, independientemente de cuántas instancias de esa clase contiene el conjunto de datos.</span><span class="sxs-lookup"><span data-stu-id="e8471-156">The macro-average metric gives the same weight to each class, no matter how many instances from that class the dataset contains.</span></span> |  <span data-ttu-id="e8471-157">**Cuanto más cerca de 1,00, mejor**.</span><span class="sxs-lookup"><span data-stu-id="e8471-157">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="e8471-158">Calcula la métrica de forma independiente para cada clase y, a continuación, toma la media (por lo tanto, se consideran todas las clases de igual forma)</span><span class="sxs-lookup"><span data-stu-id="e8471-158">It computes the metric independently for each class and then takes the average (hence treating all classes equally)</span></span> |
| <span data-ttu-id="e8471-159">**Pérdida de registro**</span><span class="sxs-lookup"><span data-stu-id="e8471-159">**Log-loss**</span></span>| <span data-ttu-id="e8471-160">La pérdida logarítmica mide el rendimiento de un modelo de clasificación donde la entrada de predicción es un valor de probabilidad de entre 0,00 y 1,00.</span><span class="sxs-lookup"><span data-stu-id="e8471-160">Logarithmic loss measures the performance of a classification model where the prediction input is a probability value between 0.00 and 1.00.</span></span> <span data-ttu-id="e8471-161">La pérdida de registro aumenta a medida que la probabilidad de predicción difiere de la etiqueta real.</span><span class="sxs-lookup"><span data-stu-id="e8471-161">Log-loss increases as the predicted probability diverges from the actual label.</span></span> | <span data-ttu-id="e8471-162">**Cuanto más cerca de 0,00, mejor**.</span><span class="sxs-lookup"><span data-stu-id="e8471-162">**The closer to 0.00, the better**.</span></span> <span data-ttu-id="e8471-163">Un modelo perfecto tendría una pérdida de registro de 0,00.</span><span class="sxs-lookup"><span data-stu-id="e8471-163">A perfect model would have a log-loss of 0.00.</span></span> <span data-ttu-id="e8471-164">El objetivo de nuestros modelos de Machine Learning es minimizar este valor.</span><span class="sxs-lookup"><span data-stu-id="e8471-164">The goal of our machine learning models is to minimize this value.</span></span>|
| <span data-ttu-id="e8471-165">**Reducción de pérdida logarítmica**</span><span class="sxs-lookup"><span data-stu-id="e8471-165">**Log-Loss Reduction**</span></span> | <span data-ttu-id="e8471-166">La [reducción de pérdida logarítmica](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) se puede interpretar como la ventaja del clasificador sobre una predicción aleatoria.</span><span class="sxs-lookup"><span data-stu-id="e8471-166">[Logarithmic loss reduction](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) can be interpreted as the advantage of the classifier over a random prediction.</span></span>| <span data-ttu-id="e8471-167">**Parte de -inf y 1,00, donde 1,00 equivale a una predicción perfecta, y 0,00 indica una predicción aproximada**.</span><span class="sxs-lookup"><span data-stu-id="e8471-167">**Ranges from -inf and 1.00, where 1.00 is perfect predictions and 0.00 indicates mean predictions**.</span></span> <span data-ttu-id="e8471-168">Por ejemplo, si el valor equivale a 0,20, se puede interpretar como "la probabilidad de que una predicción correcta sea 20 % mejor que el cálculo aleatorio"</span><span class="sxs-lookup"><span data-stu-id="e8471-168">For example, if the value equals 0.20, it can be interpreted as "the probability of a correct prediction is 20% better than random guessing"</span></span>|

<span data-ttu-id="e8471-169">Por lo general, la microprecisión se alinea mejor con las necesidades empresariales de predicciones de ML.</span><span class="sxs-lookup"><span data-stu-id="e8471-169">Micro-accuracy is generally better aligned with the business needs of ML predictions.</span></span> <span data-ttu-id="e8471-170">Si desea seleccionar una sola métrica para elegir la calidad de una tarea de clasificación multiclase, normalmente debería ser la de microprecisión.</span><span class="sxs-lookup"><span data-stu-id="e8471-170">If you want to select a single metric for choosing the quality of a multiclass classification task, it should usually be micro-accuracy.</span></span>

<span data-ttu-id="e8471-171">Ejemplo, para una tarea de clasificación de incidencias de soporte técnico: (asigna incidencias entrantes a los equipos de soporte técnico)</span><span class="sxs-lookup"><span data-stu-id="e8471-171">Example, for a support ticket classification task: (maps incoming tickets to support teams)</span></span>

- <span data-ttu-id="e8471-172">Microprecisión: ¿con qué frecuencia se clasifica una incidencia entrante en el equipo adecuado?</span><span class="sxs-lookup"><span data-stu-id="e8471-172">Micro-accuracy -- how often does an incoming ticket get classified to the right team?</span></span>
- <span data-ttu-id="e8471-173">Macroprecisión: para un equipo promedio, ¿con qué frecuencia es correcta una incidencia entrante para su equipo?</span><span class="sxs-lookup"><span data-stu-id="e8471-173">Macro-accuracy -- for an average team, how often is an incoming ticket correct for their team?</span></span>

<span data-ttu-id="e8471-174">La macroprecisión proporciona más peso a los equipos pequeños en este ejemplo: un equipo pequeño que obtiene solo 10 incidencias al año cuenta tanto como un equipo grande con 10 000 incidencias al año.</span><span class="sxs-lookup"><span data-stu-id="e8471-174">Macro-accuracy overweights small teams in this example; a small team that gets only 10 tickets per year counts as much as a large team with 10k tickets per year.</span></span> <span data-ttu-id="e8471-175">En este caso, la microprecisión se correlaciona mejor con la necesidad empresarial que se pregunta "cuánto tiempo y dinero puede ahorrar la compañía automatizando mi proceso de enrutamiento de incidencias".</span><span class="sxs-lookup"><span data-stu-id="e8471-175">Micro-accuracy in this case correlates better with the business need of, "how much time/money can the company save by automating my ticket routing process".</span></span>

<span data-ttu-id="e8471-176">Para obtener más información sobre las métricas de clasificación multiclase, lea los artículos siguientes:</span><span class="sxs-lookup"><span data-stu-id="e8471-176">For further details on multi-class classification metrics read the following articles:</span></span>

- [<span data-ttu-id="e8471-177">Micropromedio y macropromedio de precisión, recuperación y puntuación F</span><span class="sxs-lookup"><span data-stu-id="e8471-177">Micro- and Macro-average of Precision, Recall, and F-Score</span></span>](https://rushdishams.blogspot.com/2011/08/micro-and-macro-average-of-precision.html)
- [<span data-ttu-id="e8471-178">Clasificación multiclase con un conjunto de datos desequilibrado</span><span class="sxs-lookup"><span data-stu-id="e8471-178">Multiclass Classification with Imbalanced Dataset</span></span>](https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a)

## <a name="evaluation-metrics-for-regression-and-recommendation"></a><span data-ttu-id="e8471-179">Métricas de evaluación de regresión y recomendación</span><span class="sxs-lookup"><span data-stu-id="e8471-179">Evaluation metrics for Regression and Recommendation</span></span>

<span data-ttu-id="e8471-180">Las tareas de regresión y las de recomendación predicen un número.</span><span class="sxs-lookup"><span data-stu-id="e8471-180">Both the regression and recommendation tasks predict a number.</span></span> <span data-ttu-id="e8471-181">En caso de regresión, el número puede ser cualquier propiedad de salida influida por las propiedades de entrada.</span><span class="sxs-lookup"><span data-stu-id="e8471-181">In the case of regression, the number can be any output property that is influenced by the input properties.</span></span> <span data-ttu-id="e8471-182">En caso de recomendación, el número suele ser un valor de clasificación (entre 1 y 5, por ejemplo) o una recomendación de sí/no (representada por 1 y 0, respectivamente).</span><span class="sxs-lookup"><span data-stu-id="e8471-182">For recommendation, the number is usually a rating value (between 1 and 5 for example), or a yes/no recommendation (represented by 1 and 0 respectively).</span></span>

| <span data-ttu-id="e8471-183">Métrica</span><span class="sxs-lookup"><span data-stu-id="e8471-183">Metric</span></span>   |      <span data-ttu-id="e8471-184">Descripción</span><span class="sxs-lookup"><span data-stu-id="e8471-184">Description</span></span>      |  <span data-ttu-id="e8471-185">Buscar</span><span class="sxs-lookup"><span data-stu-id="e8471-185">Look for</span></span> |
|----------|-----------------------|-----------|
| <span data-ttu-id="e8471-186">**R cuadrado**</span><span class="sxs-lookup"><span data-stu-id="e8471-186">**R-Squared**</span></span> |  <span data-ttu-id="e8471-187">[R cuadrado (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination), o el *coeficiente de determinación* representan la eficacia predictiva del modelo como un valor comprendido entre -inf y 1,00.</span><span class="sxs-lookup"><span data-stu-id="e8471-187">[R-squared (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination), or *Coefficient of determination* represents the predictive power of the model as a value between -inf and 1.00.</span></span> <span data-ttu-id="e8471-188">1,00 significa que hay un ajuste perfecto y, dado que el ajuste puede ser arbitrariamente deficiente, las puntuaciones pueden ser negativas.</span><span class="sxs-lookup"><span data-stu-id="e8471-188">1.00 means there is a perfect fit, and the fit can be arbitrarily poor so the scores can be negative.</span></span> <span data-ttu-id="e8471-189">Una puntuación de 0,00 significa que el modelo consiste en adivinar el valor esperado para la etiqueta.</span><span class="sxs-lookup"><span data-stu-id="e8471-189">A score of 0.00 means the model is guessing the expected value for the label.</span></span> <span data-ttu-id="e8471-190">R2 mide la proximidad de los valores de datos de prueba reales a los valores de predicción.</span><span class="sxs-lookup"><span data-stu-id="e8471-190">R2 measures how close the actual test data values are to the predicted values.</span></span> | <span data-ttu-id="e8471-191">**Cuanto más cerca de 1,00, es mejor la calidad**.</span><span class="sxs-lookup"><span data-stu-id="e8471-191">**The closer to 1.00, the better quality**.</span></span> <span data-ttu-id="e8471-192">Sin embargo, a veces valores bajos de R cuadrado (por ejemplo, 0,50) pueden ser completamente normales o lo suficientemente buenos en un escenario, y los valores altos de R cuadrado no siempre son buenos y pueden ser sospechosos.</span><span class="sxs-lookup"><span data-stu-id="e8471-192">However, sometimes low R-squared values (such as 0.50) can be entirely normal or good enough for your scenario and high R-squared values are not always good and be suspicious.</span></span> |
| <span data-ttu-id="e8471-193">**Pérdida absoluta**</span><span class="sxs-lookup"><span data-stu-id="e8471-193">**Absolute-loss**</span></span> |  <span data-ttu-id="e8471-194">La [pérdida absoluta](https://en.wikipedia.org/wiki/Mean_absolute_error) o la *desviación media (MAE)* mide la proximidad de las predicciones a los resultados reales.</span><span class="sxs-lookup"><span data-stu-id="e8471-194">[Absolute-loss](https://en.wikipedia.org/wiki/Mean_absolute_error) or *Mean absolute error (MAE)* measures how close the predictions are to the actual outcomes.</span></span> <span data-ttu-id="e8471-195">Se trata de la media de todos los errores del modelo, donde el error del modelo es la distancia absoluta entre el valor de la etiqueta predicho y el valor de la etiqueta correcto.</span><span class="sxs-lookup"><span data-stu-id="e8471-195">It is the average of all the model errors, where model error is the absolute distance between the predicted label value and the correct label value.</span></span> <span data-ttu-id="e8471-196">Este error de predicción se calcula para cada registro del conjunto de datos de prueba.</span><span class="sxs-lookup"><span data-stu-id="e8471-196">This prediction error is calculated for each record of the test data set.</span></span> <span data-ttu-id="e8471-197">Por último, el valor medio se calcula para todas las desviaciones medias registradas.</span><span class="sxs-lookup"><span data-stu-id="e8471-197">Finally, the mean value is calculated for all recorded absolute errors.</span></span>| <span data-ttu-id="e8471-198">**Cuanto más cerca de 0,00, es mejor la calidad.**</span><span class="sxs-lookup"><span data-stu-id="e8471-198">**The closer to 0.00, the better quality.**</span></span> <span data-ttu-id="e8471-199">La desviación media utiliza la misma escala que los datos que se van a medir (no se normaliza en un intervalo específico).</span><span class="sxs-lookup"><span data-stu-id="e8471-199">The mean absolute error uses the same scale as the data being measured (is not normalized to specific range).</span></span> <span data-ttu-id="e8471-200">La pérdida absoluta, la pérdida cuadrática y la pérdida de RMS solo pueden usarse para realizar comparaciones entre los modelos del mismo conjunto de datos o el conjunto de datos y una distribución de valores de etiqueta similar.</span><span class="sxs-lookup"><span data-stu-id="e8471-200">Absolute-loss, Squared-loss, and RMS-loss can only be used to make comparisons between models for the same dataset or dataset with a similar label value distribution.</span></span> |
| <span data-ttu-id="e8471-201">**Pérdida cuadrática**</span><span class="sxs-lookup"><span data-stu-id="e8471-201">**Squared-loss**</span></span> |  <span data-ttu-id="e8471-202">La [pérdida cuadrática](https://en.wikipedia.org/wiki/Mean_squared_error) o *error cuadrático medio (MSE)*, también denominado *desviación cuadrática media (MSD)* indica la proximidad de una línea de regresión a un conjunto de valores de datos de prueba midiendo las distancias desde los puntos a la línea de regresión (estas distancias son los errores E) elevándolas al cuadrado.</span><span class="sxs-lookup"><span data-stu-id="e8471-202">[Squared-loss](https://en.wikipedia.org/wiki/Mean_squared_error) or *Mean Squared Error (MSE)*, also called *Mean Squared Deviation (MSD)*, tells you how close a regression line is to a set of test data values by taking the distances from the points to the regression line (these distances are the errors E) and squaring them.</span></span> <span data-ttu-id="e8471-203">El cuadrado proporciona más peso a las grandes diferencias.</span><span class="sxs-lookup"><span data-stu-id="e8471-203">The squaring gives more weight to larger differences.</span></span> | <span data-ttu-id="e8471-204">Siempre es un valor no negativo y los **valores próximos a 0,00 son mejores**.</span><span class="sxs-lookup"><span data-stu-id="e8471-204">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="e8471-205">En función de los datos, puede resultar imposible obtener un valor muy pequeño para el error cuadrático medio.</span><span class="sxs-lookup"><span data-stu-id="e8471-205">Depending on your data, it may be impossible to get a very small value for the mean squared error.</span></span>|
| <span data-ttu-id="e8471-206">**Pérdida de RMS**</span><span class="sxs-lookup"><span data-stu-id="e8471-206">**RMS-loss**</span></span> |  <span data-ttu-id="e8471-207">La [pérdida de RMS](https://en.wikipedia.org/wiki/Root-mean-square_deviation) o el *error de raíz cuadrada media (RMSE)* (también denominado *desviación de raíz cuadrada media, RMSD*), mide la diferencia entre los valores predichos por un modelo y los valores que se observan en el entorno que se está modelando.</span><span class="sxs-lookup"><span data-stu-id="e8471-207">[RMS-loss](https://en.wikipedia.org/wiki/Root-mean-square_deviation) or *Root Mean Squared Error (RMSE)* (also called *Root Mean Square Deviation, RMSD*), measures the difference between values predicted by a model and the values observed from the environment that is being modeled.</span></span> <span data-ttu-id="e8471-208">La pérdida de RMS es la raíz cuadrada de la pérdida cuadrática y tiene las mismas unidades de la etiqueta, similar a la pérdida absoluta aunque proporciona más peso a las grandes diferencias.</span><span class="sxs-lookup"><span data-stu-id="e8471-208">RMS-loss is the square root of Squared-loss and has the same units as the label, similar to the absolute-loss though giving more weight to larger differences.</span></span> <span data-ttu-id="e8471-209">El error de raíz cuadrada media se usa habitualmente en la climatología, la previsión y el análisis de regresión para comprobar resultados experimentales.</span><span class="sxs-lookup"><span data-stu-id="e8471-209">Root mean square error is commonly used in climatology, forecasting, and regression analysis to verify experimental results.</span></span> | <span data-ttu-id="e8471-210">Siempre es un valor no negativo y los **valores próximos a 0,00 son mejores**.</span><span class="sxs-lookup"><span data-stu-id="e8471-210">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="e8471-211">RMSD es una medida de precisión para comparar errores de previsión de diferentes modelos en determinado conjunto de datos y no entre conjuntos de datos, ya que es dependiente de la escala.</span><span class="sxs-lookup"><span data-stu-id="e8471-211">RMSD is a measure of accuracy, to compare forecasting errors of different models for a particular dataset and not between datasets, as it is scale-dependent.</span></span>|

<span data-ttu-id="e8471-212">Para obtener más información sobre las métricas de regresión, lea los artículos siguientes:</span><span class="sxs-lookup"><span data-stu-id="e8471-212">For further details on regression metrics, read the following articles:</span></span>

- [<span data-ttu-id="e8471-213">Análisis de regresión: ¿Cómo se puede interpretar el R cuadrado y evaluar la adecuación del ajuste?</span><span class="sxs-lookup"><span data-stu-id="e8471-213">Regression Analysis: How Do I Interpret R-squared and Assess the Goodness-of-Fit?</span></span>](https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)
- [<span data-ttu-id="e8471-214">Cómo interpretar el R cuadrado en el análisis de regresión</span><span class="sxs-lookup"><span data-stu-id="e8471-214">How To Interpret R-squared in Regression Analysis</span></span>](https://statisticsbyjim.com/regression/interpret-r-squared-regression)
- [<span data-ttu-id="e8471-215">Definición de R cuadrado</span><span class="sxs-lookup"><span data-stu-id="e8471-215">R-Squared Definition</span></span>](https://www.investopedia.com/terms/r/r-squared.asp)
- [<span data-ttu-id="e8471-216">Definición de error de raíz cuadrada media</span><span class="sxs-lookup"><span data-stu-id="e8471-216">Mean Squared Error Definition</span></span>](https://www.statisticshowto.datasciencecentral.com/mean-squared-error/)
- [<span data-ttu-id="e8471-217">¿Qué son el error cuadrático medio y el error de raíz cuadrada media?</span><span class="sxs-lookup"><span data-stu-id="e8471-217">What are Mean Squared Error and Root Mean Squared Error?</span></span>](https://www.vernier.com/til/1014/)

## <a name="evaluation-metrics-for-clustering"></a><span data-ttu-id="e8471-218">Métricas de evaluación para la agrupación en clústeres</span><span class="sxs-lookup"><span data-stu-id="e8471-218">Evaluation metrics for Clustering</span></span>

| <span data-ttu-id="e8471-219">Métrica</span><span class="sxs-lookup"><span data-stu-id="e8471-219">Metric</span></span>   |      <span data-ttu-id="e8471-220">Descripción</span><span class="sxs-lookup"><span data-stu-id="e8471-220">Description</span></span>      |  <span data-ttu-id="e8471-221">Buscar</span><span class="sxs-lookup"><span data-stu-id="e8471-221">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="e8471-222">**Distancia media**</span><span class="sxs-lookup"><span data-stu-id="e8471-222">**Average Distance**</span></span>|<span data-ttu-id="e8471-223">Promedio de la distancia entre los puntos de datos y el centro de su clúster asignado.</span><span class="sxs-lookup"><span data-stu-id="e8471-223">Average of the distance between data points and the center of their assigned cluster.</span></span> <span data-ttu-id="e8471-224">La distancia media es una medida de proximidad de los puntos de datos a los centroides de clúster.</span><span class="sxs-lookup"><span data-stu-id="e8471-224">The average distance is a measure of proximity of the data points to cluster centroids.</span></span> <span data-ttu-id="e8471-225">Es una medida del grado de "ajuste" del clúster.</span><span class="sxs-lookup"><span data-stu-id="e8471-225">It's a measure of how 'tight' the cluster is.</span></span>|<span data-ttu-id="e8471-226">Los valores más próximos a **0** son mejores.</span><span class="sxs-lookup"><span data-stu-id="e8471-226">Values closer to **0** are better.</span></span> <span data-ttu-id="e8471-227">Cuanto más se acerque a cero la distancia media, más agrupados estarán los datos.</span><span class="sxs-lookup"><span data-stu-id="e8471-227">The closer to zero the average distance is, the more clustered the data is.</span></span> <span data-ttu-id="e8471-228">Tenga en cuenta, sin embargo, que esta métrica disminuirá si se aumenta el número de clústeres y, en el caso extremo (en el que cada uno de los distintos puntos de datos es su propio clúster) será igual a cero.</span><span class="sxs-lookup"><span data-stu-id="e8471-228">Note though, that this metric will decrease if the number of clusters is increased, and in the extreme case (where each distinct data point is its own cluster) it will be equal to zero.</span></span>
|<span data-ttu-id="e8471-229">**Índice de Davies Bouldin**</span><span class="sxs-lookup"><span data-stu-id="e8471-229">**Davies Bouldin Index**</span></span>|<span data-ttu-id="e8471-230">La relación media entre las distancias dentro del clúster y las distancias entre clústeres.</span><span class="sxs-lookup"><span data-stu-id="e8471-230">The average ratio of within-cluster distances to between-cluster distances.</span></span> <span data-ttu-id="e8471-231">Cuanto más ajustado sea el clúster y más separados estén los clústeres, más bajo será este valor.</span><span class="sxs-lookup"><span data-stu-id="e8471-231">The tighter the cluster, and the further apart the clusters are, the lower this value is.</span></span>|<span data-ttu-id="e8471-232">Los valores más próximos a **0** son mejores.</span><span class="sxs-lookup"><span data-stu-id="e8471-232">Values closer to **0** are better.</span></span> <span data-ttu-id="e8471-233">Los clústeres que estén más separados y menos dispersos generarán una mejor puntuación.</span><span class="sxs-lookup"><span data-stu-id="e8471-233">Clusters that are farther apart and less dispersed will result in a better score.</span></span>|
|<span data-ttu-id="e8471-234">**Información mutua normalizada**</span><span class="sxs-lookup"><span data-stu-id="e8471-234">**Normalized Mutual Information**</span></span>|<span data-ttu-id="e8471-235">Se puede usar si los datos de entrenamiento usados para entrenar el modelo de agrupación en clústeres se incluyen también con etiquetas verdaderas (es decir, agrupación en clústeres supervisada).</span><span class="sxs-lookup"><span data-stu-id="e8471-235">Can be used when the training data used to train the clustering model also comes with ground truth labels (that is, supervised clustering).</span></span> <span data-ttu-id="e8471-236">La métrica de información mutua normalizada mide si se asignan puntos de datos similares al mismo clúster y puntos de datos dispares a clústeres distintos.</span><span class="sxs-lookup"><span data-stu-id="e8471-236">The Normalized Mutual Information metric measures whether similar data points get assigned to the same cluster and disparate data points get assigned to different clusters.</span></span> <span data-ttu-id="e8471-237">La información mutua normalizada es un valor entre 0 y 1</span><span class="sxs-lookup"><span data-stu-id="e8471-237">Normalized mutual information is a value between 0 and 1</span></span>|<span data-ttu-id="e8471-238">Los valores más próximos a **1** son mejores</span><span class="sxs-lookup"><span data-stu-id="e8471-238">Values closer to **1** are better</span></span>|

## <a name="evaluation-metrics-for-ranking"></a><span data-ttu-id="e8471-239">Métricas de evaluación para la clasificación</span><span class="sxs-lookup"><span data-stu-id="e8471-239">Evaluation metrics for Ranking</span></span>

| <span data-ttu-id="e8471-240">Métrica</span><span class="sxs-lookup"><span data-stu-id="e8471-240">Metric</span></span>   |      <span data-ttu-id="e8471-241">Descripción</span><span class="sxs-lookup"><span data-stu-id="e8471-241">Description</span></span>      |  <span data-ttu-id="e8471-242">Buscar</span><span class="sxs-lookup"><span data-stu-id="e8471-242">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="e8471-243">**Ganancias acumuladas descontadas**</span><span class="sxs-lookup"><span data-stu-id="e8471-243">**Discounted Cumulative Gains**</span></span>|<span data-ttu-id="e8471-244">Las ganancias acumuladas descontadas (DCG) son una medida de calidad de la clasificación.</span><span class="sxs-lookup"><span data-stu-id="e8471-244">Discounted cumulative gain (DCG) is a measure of ranking quality.</span></span> <span data-ttu-id="e8471-245">Se derivan de dos suposiciones.</span><span class="sxs-lookup"><span data-stu-id="e8471-245">It is derived from two assumptions.</span></span> <span data-ttu-id="e8471-246">Una: los elementos altamente pertinentes resultan más útiles si aparecen más arriba en orden de clasificación.</span><span class="sxs-lookup"><span data-stu-id="e8471-246">One: Highly relevant items are more useful when appearing higher in ranking order.</span></span> <span data-ttu-id="e8471-247">Dos: la utilidad realiza un seguimiento de la pertinencia, es decir, cuanto mayor es la pertinencia, más útil es un artículo.</span><span class="sxs-lookup"><span data-stu-id="e8471-247">Two: Usefulness tracks relevance that is, the higher the relevance, the more useful an item.</span></span> <span data-ttu-id="e8471-248">Las ganancias acumuladas descontadas se calculan para conseguir una posición determinada en el orden de clasificación.</span><span class="sxs-lookup"><span data-stu-id="e8471-248">Discounted cumulative gain is calculated for a particular position in the ranking order.</span></span> <span data-ttu-id="e8471-249">Suma la calificación de pertinencia dividida por el logaritmo del índice de clasificación hasta la posición de interés.</span><span class="sxs-lookup"><span data-stu-id="e8471-249">It sums the relevance grading divided by the logarithm of the ranking index up to the position of interest.</span></span> <span data-ttu-id="e8471-250">Se calcula mediante $\sum_{i=0}^{p} \frac {rel_i} {\log_{e}{i+1}}$ Las calificaciones de pertinencia se proporcionan a un algoritmo de entrenamiento de clasificación como etiquetas verdaderas.</span><span class="sxs-lookup"><span data-stu-id="e8471-250">It is calculated using $\sum_{i=0}^{p} \frac {rel_i} {\log_{e}{i+1}}$ Relevance gradings are provided to a ranking training algorithm as ground truth labels.</span></span> <span data-ttu-id="e8471-251">Un valor de DCG se proporciona para cada posición de la tabla de clasificación, de ahí el nombre de **ganancias** acumuladas descontadas.</span><span class="sxs-lookup"><span data-stu-id="e8471-251">One DCG value is provided for each position in the ranking table, hence the name Discounted Cumulative **Gains**.</span></span> |<span data-ttu-id="e8471-252">**Los valores más altos son mejores**</span><span class="sxs-lookup"><span data-stu-id="e8471-252">**Higher values are better**</span></span>|
|<span data-ttu-id="e8471-253">**Ganancias acumuladas descontadas normalizadas**</span><span class="sxs-lookup"><span data-stu-id="e8471-253">**Normalized Discounted Cumulative Gains**</span></span>|<span data-ttu-id="e8471-254">La normalización de DCG permite la comparación de la métrica para las listas de clasificación de diferentes longitudes</span><span class="sxs-lookup"><span data-stu-id="e8471-254">Normalizing DCG allows the metric to be compared for ranking lists of different lengths</span></span>|<span data-ttu-id="e8471-255">**Los valores más próximos a 1 son mejores**</span><span class="sxs-lookup"><span data-stu-id="e8471-255">**Values closer to 1 are better**</span></span>|

## <a name="evaluation-metrics-for-anomaly-detection"></a><span data-ttu-id="e8471-256">Métricas de evaluación de detección de anomalías</span><span class="sxs-lookup"><span data-stu-id="e8471-256">Evaluation metrics for Anomaly Detection</span></span>

| <span data-ttu-id="e8471-257">Métrica</span><span class="sxs-lookup"><span data-stu-id="e8471-257">Metric</span></span>   |      <span data-ttu-id="e8471-258">Descripción</span><span class="sxs-lookup"><span data-stu-id="e8471-258">Description</span></span>      |  <span data-ttu-id="e8471-259">Buscar</span><span class="sxs-lookup"><span data-stu-id="e8471-259">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="e8471-260">**Área bajo la curva de ROC**</span><span class="sxs-lookup"><span data-stu-id="e8471-260">**Area Under ROC Curve**</span></span>|<span data-ttu-id="e8471-261">El área bajo la curva receptor-operador mide el grado de eficacia del modelo al separar los puntos de datos anómalos y los habituales.</span><span class="sxs-lookup"><span data-stu-id="e8471-261">Area under the receiver operator curve measures how well the model separates anomalous and usual data points.</span></span>|<span data-ttu-id="e8471-262">**Los valores más próximos a 1 son mejores**.</span><span class="sxs-lookup"><span data-stu-id="e8471-262">**Values closer to 1 are better**.</span></span> <span data-ttu-id="e8471-263">Solo los valores mayores que 0,5 muestran la eficacia del modelo.</span><span class="sxs-lookup"><span data-stu-id="e8471-263">Only values greater than 0.5 demonstrate effectiveness of the model.</span></span> <span data-ttu-id="e8471-264">Los valores de 0,5 o menos indican que el modelo no es mejor que la asignación aleatoria de las entradas a categorías anómalas y habituales</span><span class="sxs-lookup"><span data-stu-id="e8471-264">Values of 0.5 or below indicate that the model is no better than randomly allocating the inputs to anomalous and usual categories</span></span>|
|<span data-ttu-id="e8471-265">**Tasa de detección en el recuento de falsos positivos**</span><span class="sxs-lookup"><span data-stu-id="e8471-265">**Detection Rate At False Positive Count**</span></span>|<span data-ttu-id="e8471-266">La tasa de detección en el recuento de falsos positivos es la relación entre el número de anomalías identificadas correctamente y el número total de anomalías de un conjunto de prueba, indexada por cada falso positivo.</span><span class="sxs-lookup"><span data-stu-id="e8471-266">Detection rate at false positive count is the ratio of the number of correctly identified anomalies to the total number of anomalies in a test set, indexed by each false positive.</span></span> <span data-ttu-id="e8471-267">Es decir, hay un valor de la tasa de detección en el recuento de falsos positivos para cada elemento de falsos positivos.</span><span class="sxs-lookup"><span data-stu-id="e8471-267">That is, there is a value for detection rate at false positive count for each false positive item.</span></span>|<span data-ttu-id="e8471-268">**Los valores más próximos a 1 son mejores**.</span><span class="sxs-lookup"><span data-stu-id="e8471-268">**Values closer to 1 are better**.</span></span> <span data-ttu-id="e8471-269">Si no hay ningún falso positivo, este valor será 1</span><span class="sxs-lookup"><span data-stu-id="e8471-269">If there are no false positives, then this value is 1</span></span>|
